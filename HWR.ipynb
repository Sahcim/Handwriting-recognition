{"cells":[{"metadata":{"_uuid":"1d6c0b7f-a063-4f7b-9195-f9e5c388f4d6","_cell_guid":"8e4a9575-eab5-46b9-a47d-df461ef4123d","trusted":true},"cell_type":"code","source":["from PIL import Image \n","import multiprocessing\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import Grayscale, Resize, ToTensor, Normalize, Compose, Pad\n","from torch.optim import Adam, lr_scheduler\n","from tqdm import tqdm\n","import sys\n","import os\n","os.chdir(\"/kaggle/working\")\n"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["!git clone --recursive https://github.com/parlance/ctcdecode.git\n","!cd ctcdecode && pip install ."],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Pytorch Dataset class to handle 300k training images"]},{"metadata":{"trusted":true},"cell_type":"code","source":["class handWriting_dataset(Dataset):\n","    \n","    def __init__(self,split=None,transform=None):\n","        \n","        splits = ['train', 'validation', 'test']   \n","\n","        if not (any(map(lambda x: x != split, splits))):\n","            raise Exception('Specify which split you want to use train/val/test')\n","        \n","        dataset = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_'+split+'_v2.csv')\n","        #Droping nan rows\n","        dataset.dropna(axis=0, inplace=True)\n","        #Droping columns with unreadable tag\n","        dataset = dataset[dataset['IDENTITY'] != 'UNREADABLE']\n","        #Converting to uppercase\n","        dataset['IDENTITY'] = dataset['IDENTITY'].str.upper()\n","        #reseting indexes\n","        dataset.reset_index(inplace=True, drop=True)\n","        \n","        self.filenames = dataset['FILENAME']\n","        self.labels = dataset['IDENTITY']\n","        self.transform = transform\n","        self.split = split\n","        \n","    def __getitem__(self, index):\n","        \n","        sample = Image.open('../input/handwriting-recognition/'+ self.split +'_v2/'+ self.split +'/' + self.filenames[index])\n","       \n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample, self.labels[index]\n","        \n","    def __len__(self):\n","        return self.labels.shape[0]"],"execution_count":null,"outputs":[]},{"source":["CRNN Model"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["class BidirectionalLSTM(nn.Module):\n","\n","    def __init__(self, nIn, nHidden, nOut, n_rnn=2):\n","        super(BidirectionalLSTM, self).__init__()\n","\n","        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True, num_layers=n_rnn)\n","        self.embedding = nn.Linear(nHidden * 2, nOut)\n","\n","    def forward(self, input):\n","        recurrent, _ = self.rnn(input)\n","        T, b, h = recurrent.size()\n","        t_rec = recurrent.view(T * b, h)\n","\n","        output = self.embedding(t_rec)\n","        output = output.view(T, b, -1)\n","        \n","        return output\n","\n","\n","class CRNN(nn.Module):\n","\n","    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n","        super(CRNN, self).__init__()\n","        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n","\n","        ks = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2]\n","        ps = [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n","        ss = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","        nm = [64, 64, 128, 128, 256, 256, 512, 512, 512, 512]\n","\n","        cnn = nn.Sequential()\n","\n","        def convRelu(i, batchNormalization=False, ):\n","            nIn = nc if i == 0 else nm[i - 1]\n","            nOut = nm[i]\n","            cnn.add_module('conv{0}'.format(i),\n","                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n","            \n","            if batchNormalization:\n","                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n","            if leakyRelu:\n","                cnn.add_module('relu{0}'.format(i),\n","                               nn.LeakyReLU(0.2, inplace=True))\n","            else:\n","                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n","\n","        convRelu(0)\n","        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  \n","        convRelu(1)\n","        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  \n","        convRelu(2, True)\n","        convRelu(3)\n","        cnn.add_module('dropout{0}'.format(0), nn.Dropout(0.3))  \n","        convRelu(4, True)\n","        cnn.add_module('pooling{0}'.format(2),\n","                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  \n","        cnn.add_module('dropout{0}'.format(1), nn.Dropout(0.3)) \n","        convRelu(5)\n","        cnn.add_module('dropout{0}'.format(2), nn.Dropout(0.3))  \n","        convRelu(6, True)\n","        cnn.add_module('pooling{0}'.format(3),\n","                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))\n","        cnn.add_module('dropout{0}'.format(3), nn.Dropout(0.3))\n","        convRelu(7, True) \n","        cnn.add_module('dropout{0}'.format(4), nn.Dropout(0.3))\n","        convRelu(8, True)\n","        cnn.add_module('pooling{0}'.format(4),\n","                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))\n","        cnn.add_module('dropout{0}'.format(5), nn.Dropout(0.3))\n","        convRelu(9, True)\n","         \n","\n","        self.cnn = cnn\n","        self.rnn = nn.Sequential(BidirectionalLSTM(512, nh, nclass,n_rnn))\n","        \n","\n","    def forward(self, input):\n","        # conv features\n","        conv = self.cnn(input)\n","        conv = conv.reshape(conv.size(0), 512, -1)\n","        \n","        \n","        conv = conv.permute(2, 0, 1)  # [w, b, c]\n","        # rnn features\n","        output = self.rnn(conv)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"source":["## Preprocessing and model setup"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["    class TextTransform:\n","\n","        def __init__(self,alphabet, max_target_len, number_of_timestamps):\n","\n","            self.letter_to_idx = { alphabet[i] : i for i in range(0, len(alphabet) ) }\n","            self.idx_to_letter = { i : alphabet[i] for i in range(0, len(alphabet) ) }\n","            self.max_target_len = 24\n","            self.num_of_chars = len(alphabet)\n","            self.num_of_timestamps = 64\n","\n","        def idx_seq_to_txt(self, pred):\n","            return [self.idx_to_letter[pred[i]] for i in range(0, len(pred))]\n","\n","        def txt_to_idx_seq(self, target):\n","            return [self.letter_to_idx[target[i]] for i in range(0, len(target))]\n","\n","        def preprocess_batch(self, target_batch):\n","            preprocessed_batch = []\n","            target_lengths = []\n","            for target in target_batch:\n","\n","                #preprocessed_batch.append(self.pad_idx_seq(self.txt_to_idx_seq(target)))\n","                target_lengths.append(len(target))\n","                for letter in target:\n","                    preprocessed_batch.append(self.letter_to_idx[letter])\n","\n","            return np.array(preprocessed_batch),np.array(target_lengths)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Model Setup"]},{"metadata":{"trusted":true},"cell_type":"code","source":["alphabet= u\"_ABCDEFGHIJKLMNOPQRSTUVWXYZ-'` \"\n","num_of_chars = len(alphabet)\n","TTransform = TextTransform(alphabet = alphabet, max_target_len = 24,  number_of_timestamps = 64)\n","\n","#DATASET INIT\n","IMAGE_SIZE = (64,256)\n","\n","class Crop:\n","    def __init__(self, img_size):\n","        self.img_size = img_size\n","    \n","    def __call__(self, sample):\n","        w, h = sample.size\n","        sample = sample.crop((0,h - self.img_size[0] ,self.img_size[1], h))\n","        \n","        return sample\n","        \n","\n","transform = Compose([\n","                Grayscale(),\n","                Pad((0,64,256,0), fill=255),\n","                Crop(IMAGE_SIZE),\n","                ToTensor(),\n","                Normalize([0],[255]),\n","                            ]) \n","\n","\n","train_set = handWriting_dataset(split = 'train', transform = transform)\n","val_set = handWriting_dataset(split = 'validation', transform = transform)\n","\n","#MODEL INIT\n","model = CRNN(64, 1, num_of_chars, nh=512, n_rnn=2, leakyRelu=True).to(device)\n","print(model)\n","print(\"Number of parameters = \",sum([param.nelement() for param in model.parameters()]))\n","\n","model.load_state_dict(torch.load('../input/finalfinal111/MODEL_EPOCH6_0.1054_0.1868'))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def train(input_tensor, target_tensor, input_lengths, target_lengths, model, loss_function, optimizer):\n","        \n","        model.train()\n","        model.zero_grad()\n","        \n","        model_outputs = model.forward(input_tensor)\n","        \n","        log_preds = model_outputs.log_softmax(2)\n","    \n","        loss = loss_function(log_preds, target_tensor, input_lengths, target_lengths).to(device)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        return loss\n","    \n","def val(input_tensor, target_tensor, input_lengths, target_lengths, model, loss_function):\n","    \n","        model.eval()\n","        \n","        model_outputs = model.forward(input_tensor)\n","        \n","        log_preds = model_outputs.log_softmax(2)\n","        \n","        loss = loss_function(log_preds, target_tensor, input_lengths, target_lengths).to(device)\n","        \n","        return loss\n","        \n","        \n","def trainIters(model, text_transform, train_dataset, val_dataset, num_epochs, learning_rate=0.01, batch_size=64):\n","    \n","    num_of_timestamps = 134\n","\n","    train_loader = DataLoader(dataset = train_set, batch_size = batch_size,shuffle = True,num_workers=1)\n","    val_loader = DataLoader(dataset = val_set, batch_size = batch_size,shuffle = True,num_workers=1)\n","    \n","    loss_function = nn.CTCLoss(blank = 0, reduction='mean', zero_infinity = True).to(device)\n","    \n","    \n","    milestones = [10, 17]\n","    optimizer = Adam(model.parameters(), lr = learning_rate)\n","    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)\n","    \n","    \n","    val_loss_history = []\n","    train_loss_history = []\n","    \n","    for epoch in range(num_epochs):\n","        \n","        #TRAIN EPOCH\n","        t = tqdm(iter(train_loader), total=int(len(train_loader)), leave = False)\n","        \n","        train_running_loss = 0.0\n","        counter = 0\n","        \n","        for i_step, data in enumerate(t):\n","            \n","            inputs, targets = data\n","\n","            \n","            inputs = inputs.to(device)\n","            input_lengths = torch.full(size=(inputs.size(0),), fill_value=num_of_timestamps, dtype=torch.long).to(device)\n","                   \n","            targets, target_lengths  = text_transform.preprocess_batch(targets)\n","            targets = torch.tensor(targets).to(device)\n","      \n","            target_lengths = torch.tensor(target_lengths).to(device)\n","\n","            loss = train(inputs, targets, input_lengths, target_lengths, model, loss_function, optimizer)\n","            \n","            train_running_loss += loss.item()\n","            counter += 1\n","            \n","            t.set_postfix(loss = (train_running_loss/counter))\n","        \n","        train_loss = train_running_loss / len(train_loader)\n","        \n","        # VAL EPOCH\n","        t = tqdm(iter(val_loader), total=int(len(val_loader)), leave = False)\n","\n","        val_running_loss = 0.0\n","        for i_step, data in enumerate(t):\n","            \n","            inputs, targets = data\n","            \n","            inputs = inputs.to(device)\n","            input_lengths = torch.full(size=(inputs.size(0),), fill_value=num_of_timestamps, dtype=torch.long).to(device)\n","            \n","            targets, target_lengths  = text_transform.preprocess_batch(targets)\n","            targets = torch.tensor(targets).to(device)\n","      \n","            target_lengths = torch.tensor(target_lengths).to(device)\n","\n","            loss = val(inputs, targets, input_lengths, target_lengths, model, loss_function)\n","                \n","            val_running_loss += loss.item()\n","        \n","        val_loss = val_running_loss / len(val_loader)\n","        \n","        scheduler.step()\n","        \n","        val_loss_history.append(val_loss)\n","        train_loss_history.append(train_loss)\n","        \n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)  \n","        print('Training Loss: {:.4f}'.format(train_loss))\n","        print('Validation Loss: {:.4f}'.format(val_loss))\n","        print('-' * 10)  \n","        sys.stdout.flush()\n","        \n","        \n","        torch.save(model.state_dict(), '../input/hwrfinal/MODEL_EPOCH{}_{:.4f}_{:.4f}'.format(epoch,train_loss,val_loss))\n","        \n","    return val_loss_history, train_loss_history"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["val_loss_history, train_loss_history = trainIters(model, TTransform, train_set, val_set, 30, learning_rate=0.0001, batch_size=64)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Evaluation"]},{"metadata":{"trusted":true},"cell_type":"code","source":["from ctcdecode import CTCBeamDecoder\n","\n","decoder = CTCBeamDecoder(\n","    list(alphabet),\n","    model_path=None,\n","    alpha=0,\n","    beta=0,\n","    cutoff_top_n=40,\n","    cutoff_prob=1.0,\n","    beam_width=50,\n","    num_processes=4,\n","    blank_id=0,\n","    log_probs_input=True\n",")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["model.load_state_dict(torch.load('../input/finalfinal111/MODEL_EPOCH6_0.1054_0.1868'))\n","model.eval()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def score(model, decoder, test_dataset, batch_size=64, text_transform=None):\n","    \n","    num_of_timestamps = 134\n","\n","    test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size,shuffle = True)\n","    \n","    t = tqdm(iter(test_loader), total=int(len(test_loader)), leave = False)\n","    \n","    counter = 0\n","    valid = 0\n","    letter_counter = 0\n","    valid_letter = 0\n","        \n","    for i_step, data in enumerate(t):\n","            \n","        inputs, targets = data\n","       \n","        inputs = inputs.to(device)\n","        input_lengths = torch.full(size=(inputs.size(0),), fill_value=num_of_timestamps, dtype=torch.long).to(device)\n","        \n","        model.eval()\n","        \n","        model_outputs = model.forward(inputs)\n","        preds = model_outputs.log_softmax(2)\n","        preds = preds.transpose(0, 1)\n","        \n","        beam_results, beam_scores, timesteps, out_lens = decoder.decode(preds)\n","        output = ''.join(text_transform.idx_seq_to_txt(beam_results[0][0][:out_lens[0][0]].numpy()))\n","        target = targets[0]\n","        \n","        if output == target:\n","            valid += 1\n","        \n","        for i in range(min(len(target), len(output))):\n","            if output[i] == target[i]:\n","                valid_letter += 1\n","        \n","        letter_counter += len(target)\n","        counter += 1\n","        \n","        t.set_postfix({'accuracy': valid/counter, 'letter_accuracy': valid_letter/letter_counter})\n","        \n","    return valid/counter, valid_letter/letter_counter\n","    "],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test_set = handWriting_dataset(split = 'test', transform = transform)\n","acc, letter_acc = score(model, decoder, test_set, batch_size=1, text_transform=TTransform)\n","print(\"Accuracy:\", acc)\n","print('Letter_acc:', letter_acc)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","width=2\n","height=5\n","rows = 6\n","cols = 5\n","axes=[]\n","fig=plt.figure(figsize=(15,8))\n","\n","for a in range(rows*cols):\n","    axes.append( fig.add_subplot(rows, cols, a+1) )\n","    subplot_title=(\"Label: {} \\n Pred: {}\".format(targets[a], ''.join(TTransform.idx_seq_to_txt(beam_results[a][0][:out_lens[a][0]].numpy()))))\n","    axes[-1].set_title(subplot_title)  \n","    plt.imshow(inputs[a].reshape(64,256).cpu(), cmap = 'gray', interpolation='nearest')\n","    axes[-1].set_axis_off()\n","fig.tight_layout()    \n","plt.savefig('example_results')\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}